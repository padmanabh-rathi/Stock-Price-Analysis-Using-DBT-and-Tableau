# -*- coding: utf-8 -*-
"""Stock_Price_Prediction_Lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L6xD0Mp-odsP7aUT47lIE1I9D6rFrg1Q
"""

# Importing necessary libraries
from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook
from datetime import timedelta, datetime
import requests

# Function to return Snowflake connection
def return_snowflake_conn():
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')
    return hook.get_conn().cursor()

# List of stock symbols to extract data for
symbols = ['AAPL', 'META']

# Extract stock data task for multiple companies
@task
def extract(api_key):
    all_data = {}
    for symbol in symbols:
        url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}'
        r = requests.get(url)
        data = r.json()

        if 'Time Series (Daily)' not in data:
            raise ValueError(f"Error retrieving data for {symbol}: {data.get('Error Message', 'Unknown error')}")

        # Store data for each symbol
        all_data[symbol] = data['Time Series (Daily)']

    return all_data

# Extract last 90 days of stock prices for each symbol
@task
def extract_last_90d_price(stock_data):
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)
    results = {}

    # Loop through each symbol's data
    for symbol, data in stock_data.items():
        symbol_data = []
        for d in sorted(data, reverse=True):
            stock_date = datetime.strptime(d, "%Y-%m-%d")
            if start_date <= stock_date <= end_date:
                stock_info = data[d]
                stock_info["date"] = d
                stock_info["symbol"] = symbol  # Add stock symbol to each record
                symbol_data.append(stock_info)
            if len(symbol_data) == 90:  # Limit to 90 days of data
                break
        results[symbol] = symbol_data
    return results

# Load stock data into Snowflake for each symbol separately
@task
def load_stock_data(data, table_name):
    cur = return_snowflake_conn()

    # Update the SQL statement to include the new column 'symbol'
    merge_sql = f"""
    MERGE INTO {table_name} AS target
    USING (SELECT %(symbol)s AS symbol, %(date)s AS date, %(open)s AS open, %(high)s AS high, %(low)s AS low, %(close)s AS close, %(volume)s AS volume) AS source
    ON target.date = source.date AND target.symbol = source.symbol
    WHEN MATCHED THEN
        UPDATE SET
            open = source.open,
            high = source.high,
            low = source.low,
            close = source.close,
            volume = source.volume,
            load = current_timestamp
    WHEN NOT MATCHED THEN
        INSERT (symbol, date, open, high, low, close, volume, load)
        VALUES (source.symbol, source.date, source.open, source.high, source.low, source.close, source.volume, current_timestamp);
    """

    # Insert data for each record in the list
    for symbol, records in data.items():
        for record in records:
            record_to_insert = {
                'symbol': record['symbol'],
                'date': record['date'],
                'open': record['1. open'],
                'high': record['2. high'],
                'low': record['3. low'],
                'close': record['4. close'],
                'volume': record['5. volume']
            }
            cur.execute(merge_sql, record_to_insert)
    cur.execute("COMMIT;")
    print(f"Data inserted successfully into {table_name}!")

# Defining the DAG
with DAG(
    dag_id='Stock_prediction_multi_company',
    start_date=datetime(2024, 10, 8),
    catchup=False,
    schedule_interval='@daily',  # Changed to run daily
    default_args={
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
    },
    tags=['ETL']
) as dag:

    api_key = Variable.get("api_key")
    target_table = "dev.raw_data.multi_stock_price_data"

    # Define the task objects without calling them
    raw_data_task = extract(api_key)
    last_90d_data_task = extract_last_90d_price(raw_data_task)
    load_stock_task = load_stock_data(last_90d_data_task, target_table)

    # Set up task dependencies using task objects
    raw_data_task >> last_90d_data_task >> load_stock_task